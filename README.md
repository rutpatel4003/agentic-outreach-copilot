# ğŸ¤– Cold Outreach Copilot

> **AI-Powered Job Application Assistant with Safety Guardrails**
> Automate personalized outreach at scale while maintaining message quality and fact-checking.

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Docker](https://img.shields.io/badge/docker-ready-brightgreen.svg)](https://www.docker.com/)

---

## ğŸ¯ Overview

**Cold Outreach Copilot** is a production-grade AI system that automates the job application outreach process while maintaining high-quality, personalized communication. It combines **multi-agent orchestration**, **web scraping**, **LLM-powered generation**, and **quality guardrails** to generate fact-checked, personalized messages for job opportunities.

### ğŸ”¥ Key Highlights

- **Multi-Agent Architecture**: Built with LangGraph for coordinating scraping, personalization, guardrails, and tracking
- **Safety-First Design**: Fact-checking guardrails prevent AI hallucination and ensure citation-backed claims
- **Production-Ready**: Docker deployment, comprehensive testing, input validation, and security features
- **Contact Discovery**: Automatically extracts relevant contacts (recruiters, hiring managers) with relevance scoring
- **Job Matching**: Identifies and scores job listings based on target role similarity
- **CRM Integration**: Full tracking system with follow-up scheduling and response analytics
- **Privacy-Focused**: Runs locally with Ollama (no external API calls, no data sharing)

---

## âœ¨ Features

### Core Capabilities

| Feature | Description |
|---------|-------------|
| **ğŸ” Intelligent Web Scraping** | Multi-strategy scraping (subdomains, path patterns, homepage parsing) with JavaScript rendering support for SPA sites |
| **ğŸ‘¥ Contact Extraction** | Automatically identifies recruiters, hiring managers, and key people from team/about pages with relevance scoring |
| **ğŸ’¼ Job Discovery** | Extracts and matches job listings to your target role with similarity scoring |
| **âœï¸ Personalized Messaging** | Generates 3 message variants per company with fact-based citations from scraped content |
| **ğŸ›¡ï¸ Quality Guardrails** | Multi-layer validation: fact-checking, tone analysis, citation requirements, generic phrase detection |
| **ğŸ“Š CRM & Analytics** | Track sent messages, responses, follow-ups, and analyze response rates by company/role |
| **ğŸ’¬ Reply Classification** | AI-powered classification of responses (interested/not interested/needs info) with suggested follow-ups |
| **ğŸ”„ Workflow Automation** | End-to-end automated pipeline with retry logic and error recovery |

### Additional Features

- **Resume Parsing**: Supports PDF, DOCX, and TXT formats with skill/experience extraction
- **Message Type Support**: LinkedIn connections, LinkedIn messages, and emails with appropriate length limits
- **Tone Customization**: Professional, casual, or enthusiastic tone modes
- **Manual URL Override**: Provide exact URLs when auto-discovery fails
- **Caching**: 7-day cache for scraped content to respect rate limits
- **Export Functionality**: CSV export of outreach history and analytics
- **Configurable Settings**: Centralized config system with environment variable support

---

## ğŸ—ï¸ Architecture

### System Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Streamlit Frontend                        â”‚
â”‚  (Resume Upload, Job Config, Message Review, CRM Dashboard)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  LangGraph Workflow Engine                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Resume  â”‚â”€â”€â–¶â”‚ Scraper  â”‚â”€â”€â–¶â”‚Personal- â”‚â”€â”€â–¶â”‚Guardrailsâ”‚ â”‚
â”‚  â”‚  Parser  â”‚   â”‚  Agent   â”‚   â”‚ ization  â”‚   â”‚  System  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  Agent   â”‚   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â”‚
â”‚                      â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚      â”‚
â”‚                      â”‚                               â”‚      â”‚
â”‚                      â–¼                               â–¼      â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚            â”‚Contact Extractorâ”‚          â”‚   Approved   â”‚   â”‚
â”‚            â”‚ Job Matcher     â”‚          â”‚   Messages   â”‚   â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                 â”‚           â”‚
â”‚                                                 â–¼           â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚                     â”‚ Tracking â”‚â—€â”€â”€â”‚  Follow-up       â”‚    â”‚
â”‚                     â”‚  Agent   â”‚   â”‚  Scheduler       â”‚    â”‚
â”‚                     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             SQLite Database (CRM)                            â”‚
â”‚  Companies â”‚ Contacts â”‚ Messages â”‚ Follow-ups â”‚ Campaigns   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent System

```python
ScraperAgent
â”œâ”€ Subdomain discovery (careers.company.com)
â”œâ”€ Path pattern matching (/careers, /about)
â”œâ”€ Homepage link extraction
â”œâ”€ JavaScript rendering (Playwright)
â””â”€ Content extraction (BeautifulSoup)

PersonalizationAgent
â”œâ”€ Resume parsing & skill extraction
â”œâ”€ LLM prompt engineering
â”œâ”€ JSON response parsing
â”œâ”€ Citation validation (min 2 per message)
â””â”€ Multi-variant generation (3 versions)

GuardrailsSystem
â”œâ”€ Word count validation (â‰¤200 words)
â”œâ”€ Citation counting ([source: page])
â”œâ”€ Generic phrase detection (regex)
â”œâ”€ Fact-checking (LLM-based)
â””â”€ Tone analysis (LLM-based)

TrackingAgent
â”œâ”€ Database persistence (SQLAlchemy)
â”œâ”€ Follow-up scheduling (7-day default)
â”œâ”€ Status management (sent/replied/no response)
â””â”€ Analytics calculation (response rates)

ReplyAgent
â”œâ”€ Reply classification (interested/not/needs info)
â”œâ”€ Sentiment analysis
â”œâ”€ Follow-up suggestion generation
â””â”€ Action recommendations
```

---

## ğŸš€ Tech Stack

| Layer | Technologies |
|-------|-------------|
| **LLM Framework** | LangGraph (multi-agent orchestration), Ollama (local inference) |
| **AI Models** | Qwen 3 4B (lightweight, fast), supports Llama 3.1, GPT-4 |
| **Web Scraping** | Playwright (browser automation), BeautifulSoup4 (HTML parsing), JavaScript rendering |
| **Backend** | Python 3.10+, SQLAlchemy (ORM), SQLite (database) |
| **Frontend** | Streamlit (interactive UI/dashboard) |
| **Testing** | pytest, unittest, 80% test coverage target |
| **DevOps** | Docker, docker-compose, GitHub Actions (CI/CD) |
| **Security** | Input validation, SQL injection prevention, rate limiting |

---

## ğŸ“¦ Installation

### Prerequisites

- Python 3.10 or higher
- [Ollama](https://ollama.ai/) installed locally
- Git

### Option 1: Local Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/cold-outreach-copilot.git
cd cold-outreach-copilot

# Install Python dependencies
pip install -r requirements.txt

# Install Playwright browsers
playwright install chromium

# Pull the AI model (Qwen 3 4B recommended)
ollama pull qwen3:4b-instruct

# Set up environment variables
cp .env.example .env
# Edit .env with your preferences

# Initialize database
python -c "from src.database.models import init_db; init_db()"

# Run the application
streamlit run app/streamlit_app.py
```

### Option 2: Docker (Recommended - Easy Setup)

**Windows:**
```cmd
docker-setup.bat
```

**Linux/Mac:**
```bash
chmod +x docker-setup.sh
./docker-setup.sh
```

**Manual Docker Setup:**
```bash
# Create environment file
cp .env.example .env

# Build and start containers
docker-compose up -d --build

# Pull AI model (first time only)
docker-compose --profile init up ollama-init

# Access the app at http://localhost:8501
```

ğŸ“– **See [DOCKER.md](DOCKER.md) for complete Docker documentation**

---

## ğŸ® Usage

### Quick Start

1. **Upload Resume**: Drag & drop your PDF/DOCX resume
2. **Configure Job**: Enter target role and company URL
3. **Generate Messages**: AI creates 3 personalized variants
4. **Review & Approve**: Check citations and quality scores
5. **Track Outreach**: View CRM dashboard with analytics

### Web Interface

```bash
streamlit run app/streamlit_app.py
```

Navigate to `http://localhost:8501` and use the multi-tab interface:

- **Generate Tab**: Create new outreach messages
- **Track Tab**: View sent messages and analytics
- **Replies Tab**: Analyze responses and get follow-up suggestions

### Python API

```python
from src.workflows.outreach_graph import OutreachWorkflow

# Initialize workflow
workflow = OutreachWorkflow(model_name="qwen3:4b-instruct")

# Run end-to-end
result = workflow.run(
    resume_path="path/to/resume.pdf",
    target_role="Software Engineer",
    company_url="https://example.com",
    message_type="linkedin_message",
    tone="professional"
)

# Access results
if result['status'] == 'tracked':
    message = result['selected_variant']['message']
    citations = result['selected_variant']['citations']
    guardrail_score = result['guardrail_result']['overall_score']
```

---

## ğŸ›¡ï¸ Guardrails System

### Multi-Layer Quality Checks

```
Message Input
    â”‚
    â”œâ”€â–º 1. Length Validation (â‰¤200 words)
    â”‚
    â”œâ”€â–º 2. Citation Counting (â‰¥2 required)
    â”‚        Format: [source: about], [source: careers]
    â”‚
    â”œâ”€â–º 3. Generic Phrase Detection
    â”‚        Flags: "I am reaching out", "hope this finds you well"
    â”‚
    â”œâ”€â–º 4. Fact-Checking (LLM-powered)
    â”‚        Verifies claims against scraped source material
    â”‚        Detects hallucinations and unverified statements
    â”‚
    â””â”€â–º 5. Tone Validation (LLM-powered)
            Ensures professional/casual/enthusiastic consistency
            Flags inappropriate language
```

### Scoring System

- **â‰¥90%**: âœ… Approved (message sent)
- **60-89%**: âš ï¸ Needs Revision (auto-retry up to 2x)
- **<60%**: âŒ Rejected (workflow fails)

---

## ğŸ“Š Database Schema

```sql
-- Core tables for CRM functionality
Company (id, name, url, domain, mission, about_text, careers_text, ...)
Contact (id, company_id, name, title, email, linkedin_url, x_handle, ...)
OutreachMessage (id, company_id, contact_id, message_content, status, ...)
FollowUp (id, original_message_id, scheduled_date, ...)
Campaign (id, name, target_role, resume_hash, stats, ...)

-- Enums
OutreachStatus: draft, sent, replied, no_response, bounced, interested, ...
MessageChannel: linkedin_connection, linkedin_message, email, x
ReplyCategory: interested, not_interested, needs_info, out_of_office
```

---

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage report
pytest tests/ --cov=src --cov-report=term-missing

# Run specific test file
pytest tests/test_scraper_agent.py -v

# Run integration tests
pytest tests/test_integration.py -v
```

**Test Coverage**: Core functionality covered with unit and integration tests

---

## ğŸ“ˆ Performance & Scalability

### Expected Performance

The system's performance depends on several factors including site complexity, model size, and hardware specifications:

- **Company scraping**: Varies by website (typically 10-30 seconds for 4 pages with JavaScript rendering)
- **Message generation**: Depends on LLM model (Qwen 3 4B: ~5-10 seconds per variant on CPU)
- **Guardrails validation**: ~2-5 seconds per message for fact-checking
- **Full workflow**: ~30-60 seconds per company end-to-end

### System Requirements

- **Minimum**: 4GB RAM, 2 CPU cores, 10GB disk space
- **Recommended**: 8GB+ RAM, 4+ CPU cores, 20GB disk space
- **GPU**: Optional (improves LLM inference speed significantly)

---

## ğŸ”’ Security & Privacy

### Security Features

âœ… **Input Validation**: Email, URL, text length validation to prevent injection attacks
âœ… **SQL Injection Prevention**: Parameterized queries with SQLAlchemy ORM
âœ… **Rate Limiting**: Respects `robots.txt` and implements request delays
âœ… **Sanitization**: Text sanitization removes dangerous characters
âœ… **Local Processing**: All data stays on your machine (Ollama runs locally)

### Privacy Considerations

- **No External APIs**: Ollama runs entirely locally
- **No Data Sharing**: Scraped data cached locally only
- **Configurable Storage**: Control where data is stored
- **GDPR-Friendly**: No personally identifiable information sent externally

### Ethical Usage

âš ï¸ **This tool is designed for ethical job application outreach only**

- âœ… Use for legitimate job applications
- âœ… Respect company preferences (check robots.txt)
- âœ… Follow platform terms of service (LinkedIn, etc.)
- âŒ Do not use for spam or unsolicited marketing
- âŒ Do not exceed rate limits or DDoS sites

---

## ğŸ“ Project Structure

```
cold_outreach_copilot/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py          # Streamlit web interface (746 lines)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/                   # AI agent implementations
â”‚   â”‚   â”œâ”€â”€ scraper_agent.py      # Web scraping + contact extraction
â”‚   â”‚   â”œâ”€â”€ personalization_agent.py  # Message generation
â”‚   â”‚   â”œâ”€â”€ tracking_agent.py     # CRM operations
â”‚   â”‚   â””â”€â”€ reply_agent.py        # Reply classification
â”‚   â”œâ”€â”€ database/                 # Data layer
â”‚   â”‚   â”œâ”€â”€ models.py             # SQLAlchemy ORM models
â”‚   â”‚   â””â”€â”€ crud.py               # Database operations (557 lines)
â”‚   â”œâ”€â”€ tools/                    # Utilities
â”‚   â”‚   â”œâ”€â”€ guardrails.py         # Quality checking system (339 lines)
â”‚   â”‚   â”œâ”€â”€ llm_interface.py      # Ollama wrapper
â”‚   â”‚   â””â”€â”€ web_scraper.py        # Playwright + BeautifulSoup
â”‚   â”œâ”€â”€ workflows/                # Orchestration
â”‚   â”‚   â””â”€â”€ outreach_graph.py     # LangGraph workflow (420 lines)
â”‚   â”œâ”€â”€ utils/                    # Helpers
â”‚   â”‚   â”œâ”€â”€ resume_parser.py      # PDF/DOCX parsing
â”‚   â”‚   â”œâ”€â”€ prompt_templates.py   # LLM prompts
â”‚   â”‚   â””â”€â”€ validators.py         # Input validation (NEW!)
â”‚   â””â”€â”€ config.py                 # Centralized configuration (NEW!)
â”œâ”€â”€ tests/                        # Unit & integration tests
â”‚   â”œâ”€â”€ test_agents.py            # Agent tests (274 lines)
â”‚   â”œâ”€â”€ test_scraper_agent.py     # Scraper tests (NEW!)
â”‚   â””â”€â”€ test_validators.py        # Validation tests (NEW!)
â”œâ”€â”€ data/                         # Application data
â”‚   â”œâ”€â”€ outreach.db               # SQLite database
â”‚   â”œâ”€â”€ uploads/                  # User resume uploads
â”‚   â””â”€â”€ scraped_content/          # Web scraping cache
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml                # GitHub Actions CI/CD
â”œâ”€â”€ Dockerfile                    # Docker image definition
â”œâ”€â”€ docker-compose.yml            # Multi-container setup
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ .env.example                  # Environment variable template
â”œâ”€â”€ Makefile                      # Common commands
â”œâ”€â”€ pyproject.toml                # Modern Python configuration
â””â”€â”€ README.md                     # This file
```

**Total**: 3,500+ lines of Python code (excluding tests)

---

## ğŸ”§ Configuration

### Environment Variables

```bash
# LLM Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=qwen3:4b-instruct
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000

# Scraper Configuration
SCRAPER_RATE_LIMIT=2.0           # Seconds between requests
SCRAPER_TIMEOUT=30000            # Milliseconds
SCRAPER_CACHE_ENABLED=true
SCRAPER_JS_RENDERING=true        # Enable for modern SPA sites

# Guardrails Configuration
MIN_CITATIONS=2                  # Minimum citations per message
MAX_WORD_COUNT=200              # Maximum message length
MIN_APPROVAL_SCORE=0.9          # Approval threshold (90%)

# Database Configuration
DATABASE_PATH=data/outreach.db

# Follow-up Configuration
AUTO_SCHEDULE_FOLLOWUPS=true
DEFAULT_FOLLOWUP_DAYS=7

# Logging
LOG_LEVEL=INFO
LOG_FILE_PATH=data/app.log
```

---

## ğŸ› ï¸ Development Commands

### Local Development Workflow

```bash
# Install dependencies
make install

# Run tests
make test

# Lint code
make lint

# Format code
make format

# Build Docker
make docker-build

# Run Docker
make docker-run

# Clean cache files
make clean
```

---

## ğŸ—ºï¸ Roadmap

### âœ… Completed Features

- [x] Multi-agent workflow with LangGraph
- [x] Web scraping with JavaScript rendering
- [x] Contact extraction with relevance scoring
- [x] Job discovery and matching
- [x] Guardrails system with fact-checking
- [x] CRM with follow-up scheduling
- [x] Reply classification
- [x] Streamlit dashboard
- [x] Input validation and security
- [x] Centralized configuration system
- [x] Docker deployment with docker-compose
- [x] Bulk company upload (CSV)
- [x] Company groups management
- [x] Message variant generation (3 per company)
- [x] Export functionality (CSV)

### ğŸ“‹ Future Enhancements

- [ ] Email auto-send integration (Gmail, SMTP)
- [ ] Chrome extension for LinkedIn
- [ ] Vector search for better resume-job matching
- [ ] A/B testing for message variants
- [ ] Success predictor (ML-based response rate prediction)
- [ ] Job board monitoring automation
- [ ] Fine-tuning support for custom models
- [ ] FastAPI REST API
- [ ] Multi-LLM support (OpenAI, Anthropic, Claude)
- [ ] Enhanced analytics dashboard
- [ ] Database migrations with Alembic
- [ ] CI/CD pipeline with GitHub Actions
- [ ] Webhook integrations (Slack, Discord)
- [ ] User authentication & multi-tenancy

---

## ğŸ› Known Issues & Limitations

| Issue | Impact | Workaround |
|-------|--------|------------|
| Some SPA sites don't render | Careers pages may be empty | Use manual URL override |
| LLM may fail JSON parsing | Generation retry needed | Retry logic handles this |
| LinkedIn rate limiting | Frequent scraping blocked | Use caching, respect delays |
| Small models hallucinate | Guardrails may reject | Use larger model or adjust thresholds |
| No email sending | Manual copy-paste needed | Planned for v2.0 |

---

## ğŸ¤ Contributing

Contributions welcome! Please follow these guidelines:

1. **Fork** the repository
2. **Create a feature branch**: `git checkout -b feature/your-feature`
3. **Write tests** for new functionality
4. **Ensure tests pass**: `pytest tests/`
5. **Lint code**: `flake8 src/`
6. **Commit with clear messages**: `git commit -m "Add feature: X"`
7. **Push** and create a **Pull Request**

---

## ğŸ“„ License

This project is licensed under the **MIT License**. See [LICENSE](LICENSE) file for details.

---

## ğŸ‘¨â€ğŸ’» Author

**Your Name**
- GitHub: [@rutpatel4003](https://github.com/rutpatel4003)
- LinkedIn: [Rut Patel](https://linkedin.com/in/rutpatel6684)

---

## ğŸ™ Acknowledgments

- **LangGraph** for multi-agent orchestration
- **Ollama** for local LLM inference
- **Playwright** for JavaScript rendering
- **Streamlit** for rapid UI development

---

## ğŸ“š Additional Resources

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [Ollama Models](https://ollama.ai/library)
- [Playwright Python](https://playwright.dev/python/)
- [SQLAlchemy ORM](https://www.sqlalchemy.org/)

---

**â­ If you find this project useful, please star it on GitHub!**
